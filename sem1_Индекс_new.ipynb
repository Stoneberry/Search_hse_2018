{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 1 Индекс\n",
    "\n",
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### чтение файла \n",
    "- конструкция __with open__ (recommended)\n",
    "- конструкция __open + close__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'fpath.txt'\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, 'r') as f:  \n",
    "    text = f.read() \n",
    "\n",
    "#по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "#по строкам, без \\n   \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.read().splitlines() \n",
    "    \n",
    "#not reccomended  \n",
    "file = open(txt_fpath, 'r')  \n",
    "text = file.read()    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### работа с файлами и папками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path  \n",
    "путь до файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath('fpath.txt'))\n",
    "\n",
    "# возвращает имя файла / папки по полному пути до него\n",
    "print(os.path.basename('/your/path/to/folder/with/fpath.txt'))\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists('your/path/to/any/folder/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "os.listdir(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем пути абсолютными, чтобы наш код не зависел от того, где лежит этот файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir) if not '.DS_Store' in fpath]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __os.walk__ возвращает генератор, это значит, что получить его элементы можно только проитерировавшись по нему  \n",
    "но его легко можно превратить в list и увидеть все его значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.walk(main_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__: \n",
    "получите обратный индекс для коллекция документов.    \n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия - один документ.\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/k_M7n63A3adGSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы:   \n",
    "    1. получить коллекцию документов   --- +\n",
    "    2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку --- +\n",
    "    3. получить матрицу терм-документ, написать функцию поиска по ней --- +\n",
    "    4. получить обратный индекс в виде словаря, где ключ - нормализованное слово,\n",
    "    значение - список файлов, в которых это слово встречается  --- +\n",
    "    5. вывести кусочек индекса в виде таблицы --- +\n",
    "    6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы --- +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'Friends/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove(text):\n",
    "    new = re.sub(r'\\ufeff', '', text)\n",
    "    new = re.sub(r'\\n', ' ', new)\n",
    "    new = re.sub(r'www.tvsubtitles.net', '', new)\n",
    "    new = re.sub(r'([\\W]|\\d)', ' ', new)\n",
    "    new = re.sub('(\\n|\\t|\\v|\\r)', ' ', new)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info_creator(main_dir):\n",
    "\n",
    "    all_ = defaultdict(str)  # episod - text\n",
    "    idx = defaultdict(str)  # idx - episod\n",
    "    seasons = defaultdict(list)  # season - [episods]\n",
    "    \n",
    "    avr = 0\n",
    "    i = 0\n",
    "    l = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(main_dir):\n",
    "        for name in files:\n",
    "            if not '.DS_Store' in name:\n",
    "                with open(os.path.join(root, name), 'r') as f:\n",
    "                    text = f.read() \n",
    "                    a = mystem.lemmatize(remove(text))\n",
    "                    avr += len(a)\n",
    "                    all_[name[:-7]] = ''.join(a)\n",
    "                    idx[i] = name[:-7]\n",
    "                    seasons[l].append(name[:-7])\n",
    "                    i += 1\n",
    "        l += 1\n",
    "    return all_, idx, seasons, avr / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info_creator(main_dir):\n",
    "\n",
    "    all_data = defaultdict(dict)  # название файла: {text, len}\n",
    "    word_count = defaultdict(dict)  # word : {id: count}\n",
    "    idx = defaultdict(str)  # idx - episod\n",
    "    seasons = defaultdict(list)  # season - [episods]\n",
    "\n",
    "    avr = 0\n",
    "    i = 0\n",
    "    l = 0\n",
    "    global mystem\n",
    "\n",
    "    for root, dirs, files in os.walk(main_dir):\n",
    "        for name in files:\n",
    "            if not '.DS_Store' in name:\n",
    "                with open(os.path.join(root, name), 'r', encoding='utf-8') as f:\n",
    "                    text = f.read() \n",
    "                    words = mystem.lemmatize(remove(text))\n",
    "                    length = len(words)\n",
    "                    avr += length\n",
    "                    all_data[name[:-7]] = {'text': ''.join(words),\n",
    "                                           'len': length}\n",
    "                    seasons[l].append(name[:-7])\n",
    "                    idx[i] = name[:-7]\n",
    "                    prob = Counter(words)\n",
    "                    for word in prob:\n",
    "                        word_count[word][name[:-7]] = prob[word]\n",
    "                    i += 1\n",
    "        l += 1\n",
    "    return all_data, word_count, idx, seasons, avr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, word_count, idx, seasons, avrdl = data_info_creator(main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/Stoneberry/Desktop/Uni/Прога/4 курс/Поиск/лекции/Friends/Friends - season 7/Friends - 7x09 - The One With All The Candy.ru.txt', 'r', encoding='utf-8')\n",
    "arr = f.read()\n",
    "f.close()\n",
    "words = mystem.lemmatize(remove(arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "друг  как все начинаться  да нечего рассказывать  он просто сотрудник   ладно ты  ты же на свидание с он собираться   значит  он не мочь не быть с придурь   джой  вести себя прилично  так у он горб  и\n"
     ]
    }
   ],
   "source": [
    "print(all_data['Friends - 1x01 - The One Where Monica Gets A Roommate']['text'][0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  мисс  можно кофе   извинять  не мочь бы вы относить это туда   давать  давать  спасибо  извинять  так так  ласа вегас     итак  я в ласа вегас  и я   лайза минелли                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_data['Friends - 1x01 - The One Where Monica Gets A Roommate']['text'][-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_search(word_count, word, episode=None, non=False):\n",
    "\n",
    "    if not isinstance(word, str):\n",
    "        raise ValueError\n",
    "    if len(word.split(' ')) > 1:\n",
    "        raise ValueError\n",
    "    if word == '':\n",
    "        return None\n",
    "\n",
    "    word = word.lower()\n",
    "    answer = word_count[word]\n",
    "    if answer != {}:\n",
    "        if episode is None:\n",
    "            return set(answer.keys())\n",
    "        return answer[episode]\n",
    "    return ValueError('There is no such word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friends - 3x17 - The One Without The Ski Trip',\n",
       " 'Friends - 4x02 - The One With The Cat.Tv',\n",
       " \"Friends - 6x03 - The One With Ross's Denial\",\n",
       " 'Friends - 6x07 - The One Where Phoebe Runs',\n",
       " 'Friends - 6x11 - The One With The Apothecary Table'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_search(word_count, 'лекарство')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_search(word_count, 'в', 'Friends - 4x01 - The One With The Jellyfish.Tv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратный индекс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Friends/wedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, старайтесь этого избегать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/with/Frinds/collection/'\n",
    "files_list = []\n",
    "\n",
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "### _check : в коллекции должно быть 165 файлов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space(text):\n",
    "    new = re.sub('\\(', '( ', text)\n",
    "    new = re.sub('\\)', ' )', new)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### постройте матрицу терм-документ\n",
    "term_doc_matrix = []\n",
    "\n",
    "\n",
    "### напишите функцию булева поиска по построенной матрице\n",
    "def boolean_search(data, text):\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the term-document matrix\n",
    "    :return: list of first 5 relevant documents\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    op = []\n",
    "    oper = ['&', 'ИЛИ', 'НЕ', '(', ')']\n",
    "    text = space(text)\n",
    "    text = text.split(' ')\n",
    "\n",
    "    for item in text:\n",
    "\n",
    "        if item not in oper:\n",
    "            if len(op) > 0 and op[-1] == 'НЕ':\n",
    "                item = data_search(data, item.lower(), non=True)\n",
    "                op.pop()\n",
    "            else:\n",
    "                item = data_search(data, item.lower())\n",
    "\n",
    "            if len(words) == 0:\n",
    "                words.append(item)\n",
    "\n",
    "            elif len(op) > 0:\n",
    "                if op[-1] == '&':\n",
    "                    answ = words[-1] & item\n",
    "                    words.pop()\n",
    "                    words.append(answ)\n",
    "                    op.pop()\n",
    "                elif op[-1] == 'ИЛИ':\n",
    "                    answ = words[-1] | item\n",
    "                    words.pop()\n",
    "                    words.append(answ)\n",
    "                    op.pop()\n",
    "                elif op[-1] == '(':\n",
    "                    op.pop()\n",
    "                    words.append(item)\n",
    "\n",
    "        elif item == ')':\n",
    "\n",
    "            if len(op) <= 0:\n",
    "                raise ValueError('Enter correct string')\n",
    "\n",
    "            if op[-1] == '(':\n",
    "                if len(words) <= 0:\n",
    "                    raise ValueError('Enter correct string')\n",
    "\n",
    "            else:\n",
    "                for i in op[::-1]:\n",
    "\n",
    "                    if i == '(':\n",
    "                        break\n",
    "                    elif i == '&':\n",
    "                        answ = words[-2] & words[-1]\n",
    "                        for i in range(2):\n",
    "                            words.pop()\n",
    "                        words.append(answ)\n",
    "                        op.pop()\n",
    "                    elif i == 'ИЛИ':\n",
    "                        answ = words[-2] | words[-1]\n",
    "                        for i in range(2):\n",
    "                            words.pop()\n",
    "                        words.append(answ)\n",
    "                        op.pop()\n",
    "                if len(op) == 0:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            op.append(item)\n",
    "    return words[-1]\n",
    "\n",
    "\n",
    "#запросы \n",
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джоуи & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джоуи) & Росс',\n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джоуи & (НЕ Росс)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friends - 1x07 - The One With The Blackout',\n",
       " 'Friends - 1x11 - The One With Mrs. Bing',\n",
       " 'Friends - 1x14 - The One With The Candy Hearts',\n",
       " 'Friends - 1x15 - The One With The Stoned Guy',\n",
       " 'Friends - 2x06 - The One With The Baby On The Bus',\n",
       " 'Friends - 3x06 - The One With The Flashback',\n",
       " 'Friends - 4x01 - The One With The Jellyfish.Tv',\n",
       " \"Friends - 5x22 - The One With Joey's Big Break\",\n",
       " 'Friends - 6x01 - The One After Vegas',\n",
       " \"Friends - 6x03 - The One With Ross's Denial\",\n",
       " 'Friends - 6x06 - The One On The Last Night',\n",
       " 'Friends - 6x07 - The One Where Phoebe Runs',\n",
       " 'Friends - 6x09 - The One Where Ross Got High',\n",
       " \"Friends - 6x21 - The One Where Ross Meets Elizabeth's Dad\",\n",
       " \"Friends - 6x22 - The One Where Paul's The Man\",\n",
       " 'Friends - 6x23 - The One With The Ring',\n",
       " \"Friends - 7x01 - The One With Monica's Thunder\",\n",
       " \"Friends - 7x03 - The One With Phoebe's Cookies\",\n",
       " \"Friends - 7x04 - The One With Rachel's Assistant\",\n",
       " 'Friends - 7x05 - The One With The Engagement Picture',\n",
       " 'Friends - 7x06 - The One With The Nap Partners',\n",
       " \"Friends - 7x07 - The One With Ross's Library Book\",\n",
       " \"Friends - 7x08 - The One Where Chandler Doesn't Like Dogs\",\n",
       " 'Friends - 7x14 - The One Where They All Turn Thirty',\n",
       " 'Friends - 7x16 - The One With The Truth About London',\n",
       " \"Friends - 7x20 - The One With Rachel's Big Kiss\",\n",
       " \"Friends - 7x22 - The One With Chandler's Dad\",\n",
       " \"Friends - 7x23 - The One With Chandler And Monica's Wedding (1)\",\n",
       " \"Friends - 7x24-25 - The One With Chandler And Monica's Wedding (2)\"}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Моника & Фиби & Рэйчел & Чендлер & Джоуи & Росс'\n",
    "boolean_search(word_count, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/inv_index3.svg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(data) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "\n",
    "    d = defaultdict(list)\n",
    "\n",
    "    for word in data.keys():\n",
    "        d[word] = [i for i in data_search(data, word)]\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = inverted_index(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friends - 4x01 - The One With The Jellyfish.Tv',\n",
       " \"Friends - 6x19 - The One With Joey's Fridge\"]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['and']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь для этого есть словарь word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind = pd.DataFrame({'term': vect.get_feature_names(),\n",
    "                        'docs': list(d.values()),\n",
    "                        'freq': data['freq']\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_ind['lenght'] = inv_ind.docs.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "      <th>freq</th>\n",
       "      <th>term</th>\n",
       "      <th>lenght</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>[Friends - 7x22 - The One With Chandler's Dad]</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>after</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <td>[Friends - 7x12 - The One Where They're Up All...</td>\n",
       "      <td>0.025580</td>\n",
       "      <td>again</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahh</th>\n",
       "      <td>[Friends - 4x04 - The One With The Ballroom Da...</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>ahh</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>[Friends - 7x15 - The One With Joey's New Brai...</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>all</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>[Friends - 6x16-17 - The One That Could Have B...</td>\n",
       "      <td>0.076152</td>\n",
       "      <td>and</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    docs      freq   term  \\\n",
       "Term                                                                        \n",
       "after     [Friends - 7x22 - The One With Chandler's Dad]  0.025744  after   \n",
       "again  [Friends - 7x12 - The One Where They're Up All...  0.025580  again   \n",
       "ahh    [Friends - 4x04 - The One With The Ballroom Da...  0.024608    ahh   \n",
       "all    [Friends - 7x15 - The One With Joey's New Brai...  0.068349    all   \n",
       "and    [Friends - 6x16-17 - The One That Could Have B...  0.076152    and   \n",
       "\n",
       "       lenght  \n",
       "Term           \n",
       "after       1  \n",
       "again       1  \n",
       "ahh        35  \n",
       "all         3  \n",
       "and        17  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_ind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое слово является самым частотным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docs      [Friends - 2x04 - The One With Phoebe's Husban...\n",
       "freq                                                 55.332\n",
       "term                                                     ты\n",
       "lenght                                                    2\n",
       "Name: ты, dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_ind.ix[inv_ind['freq'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое самым редким?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docs      [Friends - 1x16 - The One With Two Parts (1)]\n",
       "freq                                          0.0156364\n",
       "term                                                 би\n",
       "lenght                                                1\n",
       "Name: би, dtype: object"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_ind.ix[inv_ind['freq'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой набор слов есть во всех документах коллекции?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['done',\n",
       " 'oo',\n",
       " 'агрегат',\n",
       " 'базар',\n",
       " 'бублик',\n",
       " 'забавный',\n",
       " 'каво',\n",
       " 'клешня',\n",
       " 'кой',\n",
       " 'кофейня',\n",
       " 'мастерица',\n",
       " 'мега',\n",
       " 'молочко',\n",
       " 'мужесвеннен',\n",
       " 'насчет',\n",
       " 'ноль',\n",
       " 'обставлять',\n",
       " 'отвратный',\n",
       " 'переносить',\n",
       " 'повседневный',\n",
       " 'повыдергать',\n",
       " 'привязанность',\n",
       " 'пчела',\n",
       " 'расположение',\n",
       " 'соседский',\n",
       " 'съезжать',\n",
       " 'твердо',\n",
       " 'фаш',\n",
       " 'фильмец',\n",
       " 'фрэнсис',\n",
       " 'халка',\n",
       " 'червь']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inv_ind.loc[inv_ind['lenght'] == 165].term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой сезон был самым популярным у Чендлера? у Моники?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чендлер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular(name):\n",
    "\n",
    "    row = data.loc[name.lower()]\n",
    "    row = row.drop('freq')\n",
    "\n",
    "    maximum = 0\n",
    "    seas = ''\n",
    "\n",
    "    for i in range(1, 8):\n",
    "        a = row[seasons[i]].sum()\n",
    "        if maximum < a:\n",
    "            maximum = a\n",
    "            seas = i\n",
    "\n",
    "    return seas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular('чендлер')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular('моника')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кто из главных героев статистически самый популярный?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Term\n",
       "моника     3.881715\n",
       "росс       5.182460\n",
       "джоуи      3.999995\n",
       "чендлер    4.085088\n",
       "фиби       3.236180\n",
       "рэйчел     2.427932\n",
       "Name: freq, dtype: float64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[['моника', 'росс', 'джоуи', 'чендлер', 'фиби', 'рэйчел']]['freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Росс самый популярный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица с кол-вом употреблений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vect = CountVectorizer()\n",
    "X = new_vect.fit_transform(list(all_.values())) \n",
    "new_data = pd.DataFrame(X.todense()).transpose()\n",
    "new_data.columns = list(idx.values())\n",
    "new_data['Term'] = new_vect.get_feature_names()\n",
    "new_data = new_data.set_index(['Term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования\n",
    "from math import log\n",
    "\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n):\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "\n",
    "    qf - кол - во вхождений слова в документе\n",
    "    dl - длина документа\n",
    "\n",
    "    \"\"\"\n",
    "    tf = qf / dl\n",
    "    idf = log(N - n + 0.5 / n + 0.5)\n",
    "    a = (k1 + 1) * tf\n",
    "    b = tf + k1*(1 - b + b*(dl / avgdl))\n",
    "\n",
    "    return (a / b) * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0942846416971577"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_BM25(45, 566, avgdl, k1, b, N, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_text, stopwords={}, del_stopwords=True, del_digit=True):\n",
    "\n",
    "    words = [x.lower().strip(string.punctuation+'»«–…') for x in word_tokenize(input_text)]\n",
    "    lemmas = [mystem.lemmatize(x)[0] for x in words if x]\n",
    "    lemmas_arr = []\n",
    "    for lemma in lemmas:\n",
    "        if del_stopwords:\n",
    "            if lemma in stopwords:\n",
    "                continue\n",
    "        if del_digit:\n",
    "            if lemma.isdigit():\n",
    "                continue\n",
    "        lemmas_arr.append(lemma)\n",
    "    return lemmas_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim(words, doc, info_data, word_count, N, avgdl):\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "\n",
    "    k1 = 2.0\n",
    "    b = 0.75\n",
    "    ans = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word_count[word] != {}:\n",
    "\n",
    "            try: qf = word_count[word][doc]\n",
    "            except KeyError: qf = 0\n",
    "\n",
    "            dl = info_data[doc]['len']\n",
    "            n = len(word_count[word])\n",
    "            ans += score_BM25(qf, dl, avgdl, k1, b, N, n)\n",
    "\n",
    "    return ans\n",
    "\n",
    "\n",
    "def get_search_result(text, info_data, word_count, avgdl, stopwords={}, del_stop=True, amount=10):\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError\n",
    "    \n",
    "    words = preprocessing(text, stopwords=stopwords, del_stopwords=del_stop, del_digit=True)\n",
    "    answer = {}\n",
    "    N = len(info_data)\n",
    "   \n",
    "    for doc in info_data:\n",
    "        answer[doc] = compute_sim(words, doc, info_data, word_count, N, avgdl)\n",
    "\n",
    "    for index, ans in enumerate(sorted(answer.items(), reverse=True, key=lambda x: x[1])):\n",
    "        if index >= amount: break\n",
    "        yield (ans[0], info_data[ans[0]], ans[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friends - 7x10 - The One With The Holiday Armadillo 0.016545092871755835\n",
      "Friends - 6x19 - The One With Joey's Fridge 0.00999778323930336\n",
      "Friends - 3x10 - The One Where Rachel Quits 0.008855711671988632\n",
      "Friends - 2x09 - The One With Phoebe's Dad 0.005792518010119177\n",
      "Friends - 1x17 - The One With Two Parts (2) 0.004173275047876691\n",
      "Friends - 4x03 - The One With The 'Cuffs 0.004018665263927699\n",
      "Friends - 1x16 - The One With Two Parts (1) 0.003907436398525218\n",
      "Friends - 4x10 - The One With The Girl From Poughkeepsie 0.0035755676236525857\n",
      "Friends - 6x10 - The One With The Routine 0.0020095993237095795\n",
      "Friends - 4x08 - The One With Chandler In A Box 0.0017636645582629223\n"
     ]
    }
   ],
   "source": [
    "for i in get_search_result('рождественские каникулы', all_data, word_count, avgdl, stopwords=stops, del_stop=True, amount=10):\n",
    "    print(i[0], i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
